We achieved significant successes in our knowledge and information products, including Search, Maps, and YouTube, advances in AI across our software and hardware, growth in our Cloud Platform, and other important developments in privacy and cybersecurity and sustainability, among many other achievements.
• Our Ads Safety Report, where we explain how we are using evolving policies and better technology to find and remove policy-violating ads.
• Our YouTube enforcement report, which we release on a quarterly basis, includes information on channel removals, removal of comments, the policy reasons for removal, and data on appeals.
We will also make the Annual Meeting viewable to anyone interested through our Investor Relations YouTube channel at www.youtube.com/c/AlphabetIR.
He is responsible for Google Search, Assistant, Geo, Ads, Commerce, and Payments products.
Prior to joining Google in March 2012, Prabhakar founded and led Yahoo!
Since joining Google in 2006, Harvard University he has led Google’s advocacy on competition, content, copyright, and privacy.
We Already Publish Transparent and Extensive Lobbying Disclosures Google has long been a champion of disclosure and transparency.
Alphabet publicly supports the goals of the Paris Agreement, advocates for specific science-based climate policies, leads investment in carbon-free energy, and recently announced a new policy for Google advertisers, publishers and YouTube creators “that will prohibit ads for, and monetization of, content that contradicts well-established scientific consensus around the existence and causes of climate change.”3 Alphabet also discloses a list of its memberships in trade associations and policy-focused non- profits.
The New York Times reported YouTube was “successfully weaponized by racists...to undermine Black Lives Matter.” Research shows “YouTube plays a key role in exposing young people to white supremacist ideology and anti-Muslim propaganda.”1 Google’s advertising practices have prompted boycotts by advertisers concerned about discrimination, causing the company to lose advertising revenue.
We are also investing in onboarding, progressing, and retaining Googlers from underrepresented communities, including by investing in fair and consistent performance reviews, promotion, and pay outcomes.
We also developed more stringent hate speech and harassment policies for YouTube that specifically ban videos alleging that a group is superior based on qualities like race, gender, religion, or sexual orientation in order to justify discrimination, segregation, or exclusion.
Our Google Transparency Report shows how we are enforcing our guidelines, including provisions against hate speech on services like YouTube.
Over the past several years, we have added additional granularity, including our recent addition of a YouTube metric called Violative View Rate (VVR), which estimates the proportion of video views that violate YouTube’s Community Guidelines in a given quarter (excluding spam).
We have been transparent about these developments, publishing detailed information about these constant Search improvements and our overall approach to Search on our Google Search Overview website.
We also continue to innovate around how our company enforces the Community Guidelines for YouTube.
We have always used a combination of human reviewers and technology to address content on our platform that violates our guidelines, and we use a combination of smart detection technology and highly-trained human reviewers to enable YouTube to consistently enforce policies with increasing speed.
In April 2018, we launched a quarterly YouTube Community Guidelines Enforcement Report.
As part of this ongoing commitment to transparency, we expanded the report to include additional data like channel removals, the number of comments removed, the policy reason why a video or channel was removed, and appeals data.
• The Google Transparency Report hub includes detailed reports on requests for user information, government requests to remove content, traffic and disruptions, and many other topics that can potentially impact human rights.
WHEREAS: Internet media companies collect, use, and store substantial amounts of user data and track user behavior across online platforms, creating significant financial, legal, regulatory, and reputational risks, should those data be improperly collected, misused, or accessed by unauthorized parties.
The study concluded, “Google has serially harmed consumer welfare in unfairly and deceptively undermining consumers’ expectation of, and actual, privacy and data security, as well as undermining consumers’ ability to protect their own privacy and data security and that of minors.” A 2020 class action suit alleges that Google tracks and collects consumer browsing history and other web activity data no matter what safeguards consumers undertake.
Google’s Privacy Policy describes the types of data we collect and why, as well as our data privacy practices and policies.
We publish a number of policies and reports that provide meaningful visibility into how those services operate, including: • A collection of our blog posts that provide an overview of How Search Works, including how we build and operate Google Search, when and why we remove content from search results, how we update our systems to improve results, and how Google’s Search Quality Rater Guidelines help evaluate and improve search quality around the world.
• A set of YouTube Community Guidelines that outline what type of content is not allowed on YouTube.
These policies apply to all types of content on our platform, including videos, comments, links, and thumbnails.
Our YouTube Community Guidelines are a key part of our broader suite of policies and are regularly updated in consultation with outside experts.
• Our Google Ads Policies and our Google Publisher Policies provide guidelines for publishers and advertisers to help maintain trust in our ads ecosystem by, for instance, (1) outlining our approach to ensure a safe and positive experience for our users, and (2) clearly disclosing how we consider ads or destinations that we believe may to be harmful to users or displays shocking content or promotes hatred, intolerance, discrimination, or violence.
• Our Personalized Ads Policies provide substantial information on the company’s personalized advertising policies, with separate pages for sensitive interest categories.
• For the past decade, we have published an Ads Safety Report each year which outlines our efforts to prevent malicious use of our ads platforms.
We use a combination of automated and human evaluation to ensure Google Ads comply with these policies.
We also provide information about our targeted ad services, including what the algorithms allow and what they prohibit.
Multiple academic and journalistic studies of our services, including Search, Ads, YouTube, and more, have found that those services deliver high-quality results, and do not reflect political or other improper biases.
Providing proprietary information with regard to our algorithmic systems would not provide meaningful information to investors, but could disclose trade secrets, enable others to game our systems through illegitimate “search engine optimization”, bypass established protections, or reveal information with respect to our business operations and advertising products that could be used to compromise our operations and the quality of our services.
Google, Alphabet’s largest subsidiary, “holds a market share of around 90 percent in a wide range of digital markets,” a position that generated over $145 billion in 2020 advertising revenue worldwide.1 With such market dominance, Alphabet’s policies and practices—especially those related to misinformation and disinformation—significantly shape our information environment and have profound impacts on society.
• Our 2019 blog post Fighting disinformation across our products outlines how we consistently block and remove hosted content that does not meet our guidelines.
Every day we take down approximately 8 million deceptive ads to protect people from scams, and we regularly scan 100 billion apps to make sure they are safe.
• YouTube follows a “4 Rs” policy: Remove content that violates our policies, Reduce the spread of harmful misinformation and borderline material, Raise authoritative sources for news and information, and Reward trusted creators.
YouTube also provides insight into the types and amount of content that it removes due to violations of the YouTube Community Guidelines.
• We publish an Ads Safety Report, where we explain how we are using evolving policies and better technology to find and remove policy-violating ads.
For example, our Ads Safety Report published in 2021 noted that we added or updated more than 40 policies for advertisers and publishers and our team blocked or removed approximately 3.1 billion ads for violating our policies while restricting an additional 6.4 billion ads.
Supporting Statement: Google is the largest digital advertisement company in the world.
It plays a critical role in the disinformation ecosystem in providing an ad revenue stream for propaganda producers.
Please vote for: Report on external costs of disinformation – Proposal 17 (1) https://slate.com/technology/2021/11/google-ads-misinformation-defunding-artificial-intelligence.html (2) https://theconversation.com/its-not-just-a-social-media-problem-how-search-engines-spread-misinformation-152155 (3) https://ww.counterhate.com/_files/ugd/f4d9b9_2a34b078cbe43b6820297e3a3113f69.pdf (4) https://ww.counterhate.com/_files/ugd/f4d9b9_87b148255a140a880d86f7d2d2e6f2a.pdf (5) https://ww.unepfl.org/fileadmin/documents/universal_ownership_full.pdf; cf.
In fact, our business model depends on our services providing a useful and trustworthy source of information for all of our users, giving us an inherent long-term incentive to prevent the spread of disinformation through our products.
For example, we have disclosed the significant efforts dedicated to tackling the intentional spread of disinformation across Google Search, Google News, YouTube, and our advertising systems, in a blog post titled Fighting disinformation across our products and a white paper on How Google Fights Disinformation.
As we disclosed in our 2022 blog post Google at the Munich Security Conference, both Google and YouTube have specialized teams of intelligence and security experts globally who work to thwart disinformation threats and protect the people using our products.
Furthermore, Google’s public Advertising Policies address the specific issue of disinformation on our advertising platforms and focus on misrepresentative or harmful behavior by advertisers or publishers.
We publish an Ads Safety Report, where we explain how we are using evolving policies and better technology to find and remove policy-violating ads.
For example, our Ads Safety Report published in 2021 noted that we added or updated more than 40 policies for advertisers and publishers and our team blocked or removed approximately 3.1 billion ads for violating our policies while restricting an additional 6.4 billion ads.
Our YouTube Community Guidelines outline several policies that are directly applicable in some form to disinformation, including policies against hate speech, deceptive practices, scams, impersonation, spam, and harassment.
For example, in Q4 2021, we removed 77.3 million videos due to channel-level suspensions.
Google’s Transparency Report provides more detailed information about our enforcement efforts under YouTube’s Community Guidelines.
As we outlined later that year in our blog post Google’s €25 million contribution to media literacy, we were also the first company to contribute to helping launch the European Media and Information Fund to strengthen media literacy skills, fight misinformation, and support fact checking.
For your convenience, we are pleased to offer a live webcast of the Annual Meeting through our Investor Relations YouTube channel at https://www.youtube.com/c/AlphabetIR.